{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach \n",
    "\n",
    "\n",
    "- Get lyrics from 5 or 6 rappers using the Genius API\n",
    "- Use the Datamuse API to get words that rhyme with a ample of words from those lyrics\n",
    "- Get words that don't rhyme with those words also\n",
    "- Make a dataframe of wordA | wordB | rhyme\n",
    "- Train model on jupyter collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_artist_songs` and `scrape_song_lyrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_songs(artist_id, access_token=os.getenv(\"ACCESS_TOKEN\")):\n",
    "    \n",
    "    # use the genius API to get 15 to 20 song IDs for a given artist\n",
    "    # we will scrape the lyrics using these IDs later\n",
    "    url = f\"http://api.genius.com/artists/{artist_id}/songs\"\n",
    "    \n",
    "    token_string = f\"Bearer {access_token}\"\n",
    "    headers = {\n",
    "      \"Authorization\": token_string\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_song_lyrics(song_url_extension):\n",
    "    \n",
    "    # get the web page link using the songs route\n",
    "    url = f\"https://genius.com{song_url_extension}\"\n",
    "    \n",
    "    # get the text from the webpage\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Eparse HTML\n",
    "    html = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # get all divs from page which contain the lyrics\n",
    "    lyrics = html.findAll(\"div\", {\"class\": \"lyrics\"})\n",
    "    \n",
    "    # finally lets just remove any tags thatspecify verses and stuff \n",
    "    # e.g. [Verse 1: <ARTIST_NAME>]\n",
    "    lyrics = re.sub(r\"\\[.+\\]\\n\", '', lyrics[0].text)\n",
    "    \n",
    "    return lyrics.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(corpus):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    \n",
    "    # lets just get rid of any short words\n",
    "    return [word for word in vocab if len(word) > 2 and not word.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhymes(word):\n",
    "    \n",
    "    url = f\"https://api.datamuse.com/words?rel_rhy={word.lower()}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate through artists and download song lyrics \n",
    "\n",
    "Here we will simply iterate through some artists and download lyerics from a number of their songs. We will use a sample of these lyrics, and words that rhyme with them when we train our model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary containing the artist name and their genius artist_id\n",
    "artists = {\n",
    "    'MF_DOOM': 70,\n",
    "    'wu_tang': 21,\n",
    "    'outkast': 105,\n",
    "    'aesop_rock': 178,\n",
    "    'biggie': 22,\n",
    "    'big_l': 103,\n",
    "    'mos_def': 156,\n",
    "    'kendrick_lamar': 1421,\n",
    "    'tribe': 519,\n",
    "    'talib_kweli': 388\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting sample lyrics for MF_DOOM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f4fa9f184a4eb5a7bb421a39a97b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for wu_tang\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a29db049bcc476b9b8d0927bf364fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for outkast\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8976036cd64365a7565d9026a8f1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for aesop_rock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e2d54116064f3f9a8a841c000ac7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for biggie\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d7e2432ef245f1b06367eba9a7b608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for big_l\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4554d9e078a4d798e508375bf3b0c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for mos_def\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b9b8e30f1b42e28bc721716c43aa66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for kendrick_lamar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd80758af4a047458fd8b15a67f9b144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for tribe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282ce829e84c459cb32217046f759a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting sample lyrics for talib_kweli\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf78674f99746ee88f9ddeadb44133c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate through each artit\n",
    "for artist in list(artists.keys()):\n",
    "    # get some songs by that artist\n",
    "    artist_songs = get_artist_songs(artists[artist])\n",
    "    print(f\"Getting sample lyrics for {artist}\")\n",
    "    i = 0\n",
    "    # download the lyrics for these songs\n",
    "    for song in tqdm(artist_songs['response']['songs']):\n",
    "        song_url_extension = song['path']\n",
    "        success = False\n",
    "        # need to keep trying because the page randomly doesn't work\n",
    "        while success == False:\n",
    "            try:\n",
    "                lyrics = scrape_song_lyrics(song_url_extension)\n",
    "                success = True\n",
    "            except:\n",
    "                time.sleep(5)\n",
    "        with open(f\"data/lyrics/{artist}_{i}.txt\", \"w\") as text_file:\n",
    "            text_file.write(lyrics)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the vocabularly which we will look rhymes up for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets load these files and store them as a corpus in a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_corpus = []\n",
    "for filename in os.listdir('data/lyrics/'):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(f\"data/lyrics/{filename}\", \"r\") as text_file:\n",
    "            song_lyrics = text_file.read()\n",
    "        lyric_corpus.append(song_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11259\n"
     ]
    }
   ],
   "source": [
    "vocab = get_vocab(lyric_corpus)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate thorugh each word and get all the rhymes for each word \n",
    "\n",
    "To do this we will look up each word and get all the rhymes using the datamuse API. We will then create a row for each rhyme combination an assign them a rhyme group ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728d9c17932944daada1ae6a4b030b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11259.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rhyme_data = []\n",
    "rhyme_id = 1\n",
    "rhyme_group_id = 1\n",
    "for word in tqdm(vocab):\n",
    "    rhyme_response = get_rhymes(word)\n",
    "    if len(rhyme_response) > 0:\n",
    "        # list all words returned by the response\n",
    "        rhyming_words = [rhyme['word'] for rhyme in rhyme_response] + [word]\n",
    "        all_rhyme_combinations = list(itertools.combinations(rhyming_words, 2))\n",
    "        # create an entry for all possible rhyme pairs returned\n",
    "        for rhyme_pair in all_rhyme_combinations:\n",
    "            rhyme_data.append(\n",
    "                {\n",
    "                        'rhyme_id': rhyme_id,\n",
    "                        'rhyme_group_id': rhyme_group_id,\n",
    "                        'word_a': rhyme_pair[0],\n",
    "                        'word_b': rhyme_pair[1],\n",
    "                        'rhyme': 1\n",
    "                }\n",
    "            )\n",
    "            rhyme_id+=1\n",
    "        rhyme_group_id+=1\n",
    "    # lets just save the dataframe every 500 words\n",
    "    if rhyme_group_id % 500 == 0 and rhyme_group_id != 0:\n",
    "        rhyme_df = pd.DataFrame(rhyme_data)\n",
    "        rhyme_df.to_pickle('data/rhymes/rhyme_df.pkl')\n",
    "\n",
    "# convert to dataframe\n",
    "rhyme_df = pd.DataFrame(rhyme_data)\n",
    "rhyme_df = rhyme_df.drop_duplicates(subset=['word_a', 'word_b'], keep='first')\n",
    "rhyme_df.to_csv('data/rhymes/rhyme_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rhyme_id</th>\n",
       "      <th>rhyme_group_id</th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37493</td>\n",
       "      <td>10</td>\n",
       "      <td>deported</td>\n",
       "      <td>warted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37476</td>\n",
       "      <td>10</td>\n",
       "      <td>transported</td>\n",
       "      <td>unreported</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37339</td>\n",
       "      <td>10</td>\n",
       "      <td>courted</td>\n",
       "      <td>extorted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37606</td>\n",
       "      <td>10</td>\n",
       "      <td>shorted</td>\n",
       "      <td>aborted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37496</td>\n",
       "      <td>10</td>\n",
       "      <td>deported</td>\n",
       "      <td>port id</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rhyme_id  rhyme_group_id       word_a      word_b  rhyme\n",
       "0     37493              10     deported      warted      1\n",
       "1     37476              10  transported  unreported      1\n",
       "2     37339              10      courted    extorted      1\n",
       "3     37606              10      shorted     aborted      1\n",
       "4     37496              10     deported     port id      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyme_df = pd.read_csv('data/rhymes/rhyme_df.csv')\n",
    "rhyme_df.loc[rhyme_df['rhyme_group_id']==10].sample(5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now create a dataframe of negative samples (i.e. words that don't rhyme) \n",
    "\n",
    "To do this we will basically iterate through each rhyme group ID, select a sample of words from another rhyme group (that shouldn't rhyme) and assign those words to the `word_b`column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5127d71945545749ab29c83438cbc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9003.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3933721\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "non_rhyme_df = rhyme_df.copy()\n",
    "for rhyme_group in tqdm(list(rhyme_df['rhyme_group_id'].drop_duplicates())):\n",
    "    \n",
    "    words_in_group = len(rhyme_df.loc[rhyme_df['rhyme_group_id'] == rhyme_group])\n",
    "    \n",
    "    other_rhyme_samples = list(\n",
    "        non_rhyme_df.loc[non_rhyme_df['rhyme_group_id'] != rhyme_group, 'word_b'].sample(words_in_group)\n",
    "    )\n",
    "    \n",
    "    non_rhyme_df.loc[non_rhyme_df['rhyme_group_id'] == rhyme_group, 'word_b'] = other_rhyme_samples\n",
    "    \n",
    "non_rhyme_df['rhyme'] = 0\n",
    "non_rhyme_df = non_rhyme_df.drop_duplicates(subset=['word_a', 'word_b'], keep='first')\n",
    "non_rhyme_df.to_csv('data/rhymes/non_rhyme_df.csv', index=False)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
