{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JAT0G4jPKmb",
    "outputId": "9c7919c5-7278-4dcc-f885-69f6cd35a494"
   },
   "outputs": [],
   "source": [
    "#! pip3 install tqdm\n",
    "#! pip3 install tensorflow\n",
    "#! pip install numpy\n",
    "#! pip3 install pandas\n",
    "#! pip3 install sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Subtract\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TerminateOnNaN, CSVLogger\n",
    "tqdm.pandas()\n",
    "\n",
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5tJC-r1CEWv"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2YPa_dRcvAhw"
   },
   "outputs": [],
   "source": [
    "def tokenize_inputs(phrase_a, phrase_b, tokenizer):\n",
    "\n",
    "    tokenized_phrases = tokenizer.texts_to_sequences([phrase_a, phrase_b])\n",
    "\n",
    "    # now loop through inputs and pad or reduce size if required\n",
    "    tokenized_phrases_for_output = []\n",
    "    for phrase in tokenized_phrases:\n",
    "    if len(phrase) < MAX_LEN:\n",
    "        length_to_pad = MAX_LEN - len(phrase)\n",
    "        phrase_for_output = ([0] * length_to_pad) + phrase\n",
    "    elif len(phrase) > MAX_LEN:\n",
    "        phrase_for_output = phrase[-MAX_LEN:]\n",
    "    else:\n",
    "        phrase_for_output = phrase\n",
    "    tokenized_phrases_for_output.append(phrase_for_output)\n",
    "\n",
    "    return tf.constant(tokenized_phrases_for_output, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview of model**\n",
    "\n",
    "This is where we create the keras model. You will notice that I define a `common_lstm` layer. This is the siamese portion of the model which will have the same weights for both input (tokenized words). From here the output veotrs of these layers are subtracted before the resulting vector is passed through a series of dense layers which produces the fial classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qpSfDtYvDXJJ"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \n",
    "    word_a_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_a_input_tokens'\n",
    "      )\n",
    "    word_b_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_b_input_tokens'\n",
    "      )\n",
    "\n",
    "    common_lstm = LSTM(64, return_sequences=False, activation=\"relu\", name=\"common_lstm_layer\")\n",
    "\n",
    "    word_a_lstm_output = common_lstm(word_a_input_tokens)\n",
    "    word_b_lstm_output = common_lstm(word_b_input_tokens)\n",
    "\n",
    "    #concatenate_lstm_outputs\n",
    "    concat_layer = Subtract(name=\"concatenate_lastm_outputs\")(\n",
    "      [word_a_lstm_output, word_b_lstm_output]\n",
    "      )\n",
    "    \n",
    "    # dense layers before final classification\n",
    "    dense_layers = Dense(64, activation=\"relu\", name=\"first_dense_layer\")(concat_layer)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(32, activation=\"relu\", name=\"second_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(8, activation=\"relu\", name=\"third_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    classification_layer = Dense(1, activation=\"sigmoid\", name=\"classification_layer\")(dense_layers)\n",
    "    \n",
    "    model = Model(\n",
    "      inputs=[word_a_input_tokens, word_b_input_tokens], \n",
    "      outputs = classification_layer\n",
    "      )\n",
    "\n",
    "    model.compile(\n",
    "      loss=\"binary_crossentropy\",\n",
    "      metrics=[\"accuracy\"],\n",
    "      optimizer=\"Adam\"\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data \n",
    "\n",
    "Load the data from the rhyme and non-rhyme files we created previously. Note due to hardware limitations I only focused on a subset of 1,000,000 word pairs but you can use more or less than this depending on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Y9gWLLSQCYMt",
    "outputId": "693979c2-f176-49f5-8482-f39ff922b6b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rhyme_id</th>\n",
       "      <th>rhyme_group_id</th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1874345</th>\n",
       "      <td>4271883</td>\n",
       "      <td>1662</td>\n",
       "      <td>johnnie</td>\n",
       "      <td>garmany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561483</th>\n",
       "      <td>8243577</td>\n",
       "      <td>3282</td>\n",
       "      <td>peveto</td>\n",
       "      <td>veteto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931657</th>\n",
       "      <td>1348713</td>\n",
       "      <td>540</td>\n",
       "      <td>batt</td>\n",
       "      <td>placemat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714938</th>\n",
       "      <td>9228651</td>\n",
       "      <td>3665</td>\n",
       "      <td>greeter</td>\n",
       "      <td>me ter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217674</th>\n",
       "      <td>2016879</td>\n",
       "      <td>776</td>\n",
       "      <td>youngblood</td>\n",
       "      <td>clsid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rhyme_id  rhyme_group_id      word_a    word_b  rhyme\n",
       "1874345   4271883            1662     johnnie   garmany      1\n",
       "2561483   8243577            3282      peveto    veteto      1\n",
       "931657    1348713             540        batt  placemat      1\n",
       "2714938   9228651            3665     greeter    me ter      1\n",
       "1217674   2016879             776  youngblood     clsid      1"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyme_df = pd.read_csv('data/rhyme_df.csv')\n",
    "rhyme_df = rhyme_df.dropna(subset=['word_a', 'word_b', 'rhyme'])\n",
    "non_rhyme_df = pd.read_csv('data/non_rhyme_df.csv')\n",
    "non_rhyme_df = non_rhyme_df.dropna(subset=['word_a', 'word_b', 'rhyme'])\n",
    "\n",
    "df = pd.concat([\n",
    "        rhyme_df.sample(500_000, random_state=123), \n",
    "        non_rhyme_df.sample(500_000, random_state=123)\n",
    "    ])\n",
    "del rhyme_df, non_rhyme_df\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd3XN7sGdNSo"
   },
   "source": [
    "# Tokenize inputs\n",
    "\n",
    "Create and fit a tokenizer on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "182dea908f4543268f1eb00fdf208169",
      "a2164716defd42248afadcfa2a464f19",
      "2e581bb339fc41e984b75e5f473043bb",
      "762776797fd247cdaff619f3fecfe7c7",
      "5ddb350805d3455c9fbc4826761b2f25",
      "c994c61b206f412ab6fe2c3f304bc096",
      "642d732105924b85b550012f72b19ca4",
      "8a2dd43b441f4d918fa0101c26b2bafc"
     ]
    },
    "id": "dsNL_CXGDIXa",
    "outputId": "5cf492bb-ba17-4a71-efd2-272987d0635a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182dea908f4543268f1eb00fdf208169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000000.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts(df['word_a'] + df['word_b'])\n",
    "\n",
    "df['word_tokens'] = df.progress_apply(\n",
    "    lambda row: tokenize_inputs(row['word_a'], row['word_b'], tokenizer), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcDoh8M8kgp7"
   },
   "source": [
    "# Split data into train (60%) test (30%) and validation (10%) sets\n",
    "\n",
    "Use stratified random sampling to create train, test and va;idation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZFmqgCVbhioA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df['word_tokens']), list(df['rhyme']), stratify=df['rhyme'], \n",
    "    test_size=0.4, random_state=123\n",
    "    )\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test, y_test, stratify=y_test, test_size=0.25, random_state=123\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jdaS_M4Mu85D"
   },
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "y_val = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxXbS45koKHL"
   },
   "source": [
    "# Train model\n",
    "\n",
    "Call our model function and fit it on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92qfyi2EoJy-",
    "outputId": "f42f24ae-2556-46f3-d8e9-7b01da87ad73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 491s 104ms/step - loss: 0.5065 - accuracy: 0.7655 - val_loss: 0.2918 - val_accuracy: 0.8713\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 495s 106ms/step - loss: 0.3461 - accuracy: 0.8566 - val_loss: 0.2691 - val_accuracy: 0.8815\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 491s 105ms/step - loss: 0.3230 - accuracy: 0.8670 - val_loss: 0.2463 - val_accuracy: 0.8975\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 495s 106ms/step - loss: 0.3134 - accuracy: 0.8722 - val_loss: 0.2357 - val_accuracy: 0.9033\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 489s 104ms/step - loss: 0.3051 - accuracy: 0.8760 - val_loss: 0.2312 - val_accuracy: 0.9067\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 492s 105ms/step - loss: 0.2999 - accuracy: 0.8788 - val_loss: 0.2264 - val_accuracy: 0.9079\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 488s 104ms/step - loss: 0.2946 - accuracy: 0.8807 - val_loss: 0.2174 - val_accuracy: 0.9139\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 486s 104ms/step - loss: 0.2868 - accuracy: 0.8849 - val_loss: 0.2147 - val_accuracy: 0.9137\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 498s 106ms/step - loss: 0.2854 - accuracy: 0.8851 - val_loss: 0.2118 - val_accuracy: 0.9157\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 499s 106ms/step - loss: 0.2816 - accuracy: 0.8876 - val_loss: 0.2042 - val_accuracy: 0.9198\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 501s 107ms/step - loss: 0.2771 - accuracy: 0.8897 - val_loss: 0.2086 - val_accuracy: 0.9177\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2727 - accuracy: 0.8923 - val_loss: 0.2018 - val_accuracy: 0.9219\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 494s 105ms/step - loss: 0.2687 - accuracy: 0.8934 - val_loss: 0.2042 - val_accuracy: 0.9204\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 500s 107ms/step - loss: 0.2671 - accuracy: 0.8941 - val_loss: 0.1925 - val_accuracy: 0.9273\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 500s 107ms/step - loss: 0.2644 - accuracy: 0.8955 - val_loss: 0.1916 - val_accuracy: 0.9254\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 503s 107ms/step - loss: 0.2618 - accuracy: 0.8975 - val_loss: 0.1896 - val_accuracy: 0.9291\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2583 - accuracy: 0.8990 - val_loss: 0.1832 - val_accuracy: 0.9307\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2547 - accuracy: 0.9001 - val_loss: 0.1798 - val_accuracy: 0.9319\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 503s 107ms/step - loss: 0.2524 - accuracy: 0.9012 - val_loss: 0.1826 - val_accuracy: 0.9329\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 500s 107ms/step - loss: 0.2515 - accuracy: 0.9027 - val_loss: 0.1742 - val_accuracy: 0.9359\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 503s 107ms/step - loss: 0.2493 - accuracy: 0.9035 - val_loss: 0.1787 - val_accuracy: 0.9338\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2451 - accuracy: 0.9057 - val_loss: 0.1740 - val_accuracy: 0.9349\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 503s 107ms/step - loss: 0.2453 - accuracy: 0.9055 - val_loss: 0.1718 - val_accuracy: 0.9352\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 504s 107ms/step - loss: 0.2419 - accuracy: 0.9073 - val_loss: 0.1737 - val_accuracy: 0.9349\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 506s 108ms/step - loss: 0.2396 - accuracy: 0.9084 - val_loss: 0.1675 - val_accuracy: 0.9393\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 506s 108ms/step - loss: 0.2378 - accuracy: 0.9088 - val_loss: 0.1643 - val_accuracy: 0.9405\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 504s 108ms/step - loss: 0.2375 - accuracy: 0.9093 - val_loss: 0.1679 - val_accuracy: 0.9396\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 496s 106ms/step - loss: 0.2355 - accuracy: 0.9105 - val_loss: 0.1596 - val_accuracy: 0.9407\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 506s 108ms/step - loss: 0.2322 - accuracy: 0.9117 - val_loss: 0.1638 - val_accuracy: 0.9396\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 498s 106ms/step - loss: 0.2320 - accuracy: 0.9122 - val_loss: 0.1582 - val_accuracy: 0.9413\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 506s 108ms/step - loss: 0.2299 - accuracy: 0.9132 - val_loss: 0.1595 - val_accuracy: 0.9402\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 506s 108ms/step - loss: 0.2286 - accuracy: 0.9133 - val_loss: 0.1611 - val_accuracy: 0.9399\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 504s 108ms/step - loss: 0.2290 - accuracy: 0.9135 - val_loss: 0.1542 - val_accuracy: 0.9433\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 486s 104ms/step - loss: 0.2258 - accuracy: 0.9150 - val_loss: 0.1569 - val_accuracy: 0.9437\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 486s 104ms/step - loss: 0.2251 - accuracy: 0.9150 - val_loss: 0.1557 - val_accuracy: 0.9430\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 487s 104ms/step - loss: 0.2248 - accuracy: 0.9151 - val_loss: 0.1512 - val_accuracy: 0.9456\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 498s 106ms/step - loss: 0.2232 - accuracy: 0.9161 - val_loss: 0.1509 - val_accuracy: 0.9450\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 503s 107ms/step - loss: 0.2208 - accuracy: 0.9169 - val_loss: 0.1535 - val_accuracy: 0.9438\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 503s 107ms/step - loss: 0.2226 - accuracy: 0.9161 - val_loss: 0.1498 - val_accuracy: 0.9455\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 501s 107ms/step - loss: 0.2220 - accuracy: 0.9164 - val_loss: 0.1488 - val_accuracy: 0.9447\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 504s 108ms/step - loss: 0.2208 - accuracy: 0.9178 - val_loss: 0.1506 - val_accuracy: 0.9456\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 501s 107ms/step - loss: 0.2193 - accuracy: 0.9183 - val_loss: 0.1496 - val_accuracy: 0.9460\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 505s 108ms/step - loss: 0.2174 - accuracy: 0.9188 - val_loss: 0.1515 - val_accuracy: 0.9450\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 505s 108ms/step - loss: 0.2175 - accuracy: 0.9186 - val_loss: 0.1523 - val_accuracy: 0.9438\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 505s 108ms/step - loss: 0.2165 - accuracy: 0.9188 - val_loss: 0.1515 - val_accuracy: 0.9456\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 504s 107ms/step - loss: 0.2135 - accuracy: 0.9206 - val_loss: 0.1483 - val_accuracy: 0.9481\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2158 - accuracy: 0.9192 - val_loss: 0.1483 - val_accuracy: 0.9470\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 507s 108ms/step - loss: 0.2133 - accuracy: 0.9202 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 504s 108ms/step - loss: 0.2129 - accuracy: 0.9209 - val_loss: 0.1458 - val_accuracy: 0.9475\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2128 - accuracy: 0.9204 - val_loss: 0.1394 - val_accuracy: 0.9490\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 503s 107ms/step - loss: 0.2130 - accuracy: 0.9212 - val_loss: 0.1431 - val_accuracy: 0.9478\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2105 - accuracy: 0.9220 - val_loss: 0.1399 - val_accuracy: 0.9500\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 504s 107ms/step - loss: 0.2097 - accuracy: 0.9228 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 502s 107ms/step - loss: 0.2096 - accuracy: 0.9221 - val_loss: 0.1361 - val_accuracy: 0.9521\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 505s 108ms/step - loss: 0.2082 - accuracy: 0.9231 - val_loss: 0.1333 - val_accuracy: 0.9521\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 498s 106ms/step - loss: 0.2083 - accuracy: 0.9220 - val_loss: 0.1392 - val_accuracy: 0.9494\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 505s 108ms/step - loss: 0.2074 - accuracy: 0.9233 - val_loss: 0.1344 - val_accuracy: 0.9510\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 505s 108ms/step - loss: 0.2073 - accuracy: 0.9231 - val_loss: 0.1347 - val_accuracy: 0.9506\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 506s 108ms/step - loss: 0.2061 - accuracy: 0.9237 - val_loss: 0.1351 - val_accuracy: 0.9515\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 506s 108ms/step - loss: 0.2067 - accuracy: 0.9231 - val_loss: 0.1419 - val_accuracy: 0.9494\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 512s 109ms/step - loss: 0.2070 - accuracy: 0.9232 - val_loss: 0.1340 - val_accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 509s 109ms/step - loss: 0.2076 - accuracy: 0.9231 - val_loss: 0.1392 - val_accuracy: 0.9504\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 510s 109ms/step - loss: 0.2060 - accuracy: 0.9237 - val_loss: 0.1378 - val_accuracy: 0.9508\n",
      "Epoch 64/100\n",
      "2808/4688 [================>.............] - ETA: 3:14 - loss: 0.2045 - accuracy: 0.9239"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\"models/rhyme_model.hdf5\",monitor=\"val_loss\")\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]],\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=[model_checkpoint, terminate_on_nan, csv_logger],\n",
    "    validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gybqTytz4BXB"
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DFFz7qB1hr6S"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model(\"models/rhyme_model.hdf5\")\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "y_pred = y_pred > 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2wjPSHp2SHe",
    "outputId": "222d2460-7be6-4f13-daac-6218e3724caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95    150000\n",
      "           1       0.94      0.96      0.95    150000\n",
      "\n",
      "    accuracy                           0.95    300000\n",
      "   macro avg       0.95      0.95      0.95    300000\n",
      "weighted avg       0.95      0.95      0.95    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model on some examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Daj1qHucLWJ5",
    "outputId": "7f15c838-501b-417a-978b-28c7c919ce86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric 1: Cornish hens switchin' positions\n",
      "Lyric 2: auditionin' mortitions\n",
      "Rhyme(0.9860000014305115)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Lived happily ever after\n",
      "Lyric 2: but that's another chapter\n",
      "Rhyme(0.9860000014305115)\n",
      "---------------\n",
      "\n",
      "Lyric 1: I keep some E&J, sittin' bent up in the stairway\n",
      "Lyric 2: Y'all know my steelo, with or without the airplay\n",
      "Rhyme(0.9652000069618225)\n",
      "---------------\n",
      "\n",
      "Lyric 1: I guess every superhero need his theme music\n",
      "Lyric 2: No one man should have all that power\n",
      "Non-rhyme(0.0)\n",
      "---------------\n",
      "\n",
      "Lyric 1: In the city of L.A\n",
      "Lyric 2: In the city of good ol' Watts\n",
      "Non-rhyme(0.0)\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "   [\"Cornish hens switchin' positions\", \"auditionin' mortitions\"], # MF DOOM Rhyme\n",
    "   [\"Lived happily ever after\", \"but that's another chapter\"], # Outkast rhyme\n",
    "   [\"I keep some E&J, sittin' bent up in the stairway\", \"Y'all know my steelo, with or without the airplay\"],# Nas rhyme\n",
    "   [\"I guess every superhero need his theme music\", \"No one man should have all that power\"], # Kanye non-rhyme\n",
    "   [\"In the city of L.A\", \"In the city of good ol' Watts\"], # Tupac non-rhyme\n",
    "]\n",
    "\n",
    "sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "for i in range(len(samples)):\n",
    "    print(f\"Lyric 1: {samples[i][0]}\")\n",
    "    print(f\"Lyric 2: {samples[i][1]}\")\n",
    "    print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "    print(\"---------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_rhyme_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "182dea908f4543268f1eb00fdf208169": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e581bb339fc41e984b75e5f473043bb",
       "IPY_MODEL_762776797fd247cdaff619f3fecfe7c7"
      ],
      "layout": "IPY_MODEL_a2164716defd42248afadcfa2a464f19"
     }
    },
    "2e581bb339fc41e984b75e5f473043bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c994c61b206f412ab6fe2c3f304bc096",
      "max": 1000000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ddb350805d3455c9fbc4826761b2f25",
      "value": 1000000
     }
    },
    "5ddb350805d3455c9fbc4826761b2f25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "642d732105924b85b550012f72b19ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "762776797fd247cdaff619f3fecfe7c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a2dd43b441f4d918fa0101c26b2bafc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_642d732105924b85b550012f72b19ca4",
      "value": " 1000000/1000000 [00:50&lt;00:00, 19636.03it/s]"
     }
    },
    "8a2dd43b441f4d918fa0101c26b2bafc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2164716defd42248afadcfa2a464f19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c994c61b206f412ab6fe2c3f304bc096": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
